
## Chapter 2. Essential Probabilistic Methods for Deep Learning (확률적 방법)
- 누구나 머신러닝과 딥러닝 알고리즘을 데이터 분석 및 최적화를 위해 활용하지만, **학습모델에 대한 제대로된 이해 없이는, 머신러닝을 제대로 이해할 수 없다.**

### A Primer on Probability (확률 개론)
- 머신러닝에서 중요한 확률은 중요하다.

#### Probability distribution functions(확률 분포 함수)
- 랜덤 변수의 다양한 결과를 볼 가능성은 확률 분포로 설명됩니다. 
- 머신러닝 기법에서 **확률 분포의 특징과 속성**을 이해하는 것이 필수적입니다. 
- 확률 분포 함수는 다양한 종류의 **시계열 데이터를 설명하는 데 사용**되며, 이는 적절한 알고리즘을 선택하는 데 도움을 줍니다. 
- 이 주제는 간단하고 일관성 있게 다루기 위해 제3장에서 설명됩니다.

#### Hypothesis testing(가설 검정)
- 가설 검정은 데이터 샘플을 기반으로 모집단(population-based)에 대한 주장이 더 올바를지 틀릴지를 확립하는 데 사용
- 정상성 검정은 가설 검정을 사용하며 제3장에서 논의됩니다.

#### Decision trees(의사결정 나무)
- 의사결정 나무는 **조건부 확률**과 같은 확률적 개념을 차용한 머신러닝 알고리즘의 일종입니다.
- 의사결정 나무에 대한 자세한 내용은 제7장에서 다룰 수 있습니다.

#### Information theory(정보 이론)
- 정보 이론은 정보가 어떻게 측정되고 저장되며 전달되는지를 연구하는 복잡한 학문입니다. 
- 의사결정 나무를 포함한 **수많은 머신러닝 기법에 통합**됩니다. 
- 제3장에서 다룰 최대 정보 계수라는 **비선형 상관 관계 측정 기법에도 사용**됩니다.

### Introduction to Probabilistic Concepts

### Sampling and Hypothesis Testing

### A Primer on Information Theory

### Summary